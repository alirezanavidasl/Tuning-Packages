{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# pip install keras_tuner\r\n",
    "# pip install pandas\r\n",
    "# pip install numpy\r\n",
    "# pip install tensorflow\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def handle_input_window_size(train_input, window_size):\r\n",
    "        \"\"\" make window sized data from 2d data\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        print(window_size)\r\n",
    "        if window_size > 1:\r\n",
    "            condition = len(train_input.shape) > 1\r\n",
    "            if not condition:\r\n",
    "                train_input=train_input.reshape(-1, 1)\r\n",
    "            m, n = train_input.shape\r\n",
    "            s0, s1 = train_input.strides\r\n",
    "            _shape = (m - window_size + 1, window_size, n)\r\n",
    "            _strides = (s0, s0, s1)\r\n",
    "            return np.lib.stride_tricks.as_strided(train_input, shape=_shape, strides=_strides)\r\n",
    "        else:\r\n",
    "            train_input = np.expand_dims(train_input, 1)\r\n",
    "        return train_input"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import keras_tuner as kt\r\n",
    "import tensorflow as tf\r\n",
    "import numpy as np\r\n",
    "# import tensorflow_model_optimization as tfmot\r\n",
    "data=pd.read_csv('pjm-5min.csv')\r\n",
    "data.drop(data.iloc[:,-4:-1],axis=1,inplace=True)\r\n",
    "data.dropna(inplace=True)\r\n",
    "window_size=6\r\n",
    "\r\n",
    "\r\n",
    "class MyTuner(kt.Hyperband):\r\n",
    "  def run_trial(self, trial, *args, **kwargs):\r\n",
    "    # You can add additional HyperParameters for preprocessing and custom training loops\r\n",
    "    # via overriding `run_trial`\r\n",
    "    kwargs['batch_size'] = trial.hyperparameters.Int('batch_size', 5, 96, step=30)\r\n",
    "    # kwargs['epochs'] = trial.hyperparameters.Int('epochs', 10, 60,step=10)\r\n",
    "    super(MyTuner, self).run_trial(trial, *args, **kwargs)\r\n",
    "\r\n",
    "    \r\n",
    "def build_model(hp):\r\n",
    "    # window_size= hp.Choice(\"window_size\",[3,6,12,24])\r\n",
    "    \"\"\"Builds a convolutional model.\"\"\"\r\n",
    "    inputs1 = tf.keras.Input(shape=(data.shape[1]-2))\r\n",
    "    inputs2=  tf.keras.Input(shape=(window_size,1))\r\n",
    "\r\n",
    "    x1 = inputs1\r\n",
    "    x1 = tf.keras.layers.Dense(\r\n",
    "          units=hp.Int(\"units_den1\" , 2, 100, step=5),\r\n",
    "          activation=hp.Choice(\"active_func_den1\",[\"relu\",\"tanh\",\"sigmoid\"]),\r\n",
    "          )(x1)\r\n",
    "\r\n",
    "    x2=inputs2\r\n",
    "    x2 = tf.keras.layers.LSTM(\r\n",
    "          units=hp.Int(\"units_LSTM\" , 5, 95, step=5)\r\n",
    "        , activation=hp.Choice(\"lstm_active_func\",[\"relu\",\"tanh\",\"sigmoid\"])\r\n",
    "        , recurrent_activation=hp.Choice(\"lstm_rec_active_func\",[\"tanh\",\"sigmoid\"])\r\n",
    "        , dropout=0.1\r\n",
    "        # ,stateful=hp.Choice(\"lstm_stateful\",[True,False])\r\n",
    "        ,return_sequences=True\r\n",
    "    )(x2)\r\n",
    "    x2=tf.keras.layers.Flatten()(x2)\r\n",
    "    x2 = tf.keras.layers.Dense(\r\n",
    "          units=hp.Int(\"units_den2\" , 2, 100, step=5),\r\n",
    "          activation=hp.Choice(\"active_func_den2\",[\"relu\",\"tanh\",\"sigmoid\"]),\r\n",
    "          )(x2)\r\n",
    "\r\n",
    "    combinedInput = tf.keras.layers.concatenate([x1, x2])\r\n",
    "    x = tf.keras.layers.Dense(\r\n",
    "          units=hp.Int(\"units_den3\" , 2, 100, step=5),\r\n",
    "          activation=hp.Choice(\"active_func_den3\",[\"relu\",\"tanh\",\"sigmoid\"]),\r\n",
    "          )(combinedInput)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"linear\")(x)\r\n",
    "\r\n",
    "    model = tf.keras.Model([inputs1,inputs2], outputs)\r\n",
    "    # model= tfmot.quantization.keras.quantize_model(model)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\r\n",
    "        hp.Choice(\"initial_learning_rate\", values=[1e-2,1e-3,5e-3]),\r\n",
    "        hp.Int(\"decay_steps\", 10 , 100, step=20 ),\r\n",
    "        hp.Float(\"decay_rate\" , 0.7 ,1, step=0.05 )\r\n",
    "       )\r\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\r\n",
    "\r\n",
    "    # optimizer = hp.Choice(\"optimizer\", ['adam', 'sgd'])\r\n",
    "    # if hp.Choice(\"optimizer\", ['adam', 'sgd']) == \"adam\":\r\n",
    "    #     optimizer = tf.keras.optimizers.Adam(\r\n",
    "    #         hp.Choice(\"learning_rate\", values=[1e-3,5e-4])\r\n",
    "    #     )\r\n",
    "    # else:\r\n",
    "    #     optimizer = tf.keras.optimizers.SGD(\r\n",
    "    #         hp.Choice(\"learning_rate\", values=[1e-3,5e-4])\r\n",
    "    #     )\r\n",
    "\r\n",
    "    classes_range=[-float('inf'),hp.Int(\"range\", 40 , 200, step=10 ),float('inf')]\r\n",
    "    classes_factor=[1,hp.Int(\"factor\", 2 , 15, step=1 )]\r\n",
    "    def custom_loss(y_true, y_pred):\r\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\r\n",
    "        loss = tf.square(y_true - y_pred)\r\n",
    "        coef = tf.zeros_like(loss)\r\n",
    "        for i in range(1, len(classes_range)):\r\n",
    "            index = tf.where(tf.math.logical_and(\r\n",
    "                tf.greater_equal(y_true, tf.constant(classes_range[i - 1], dtype = y_pred.dtype)),\r\n",
    "                tf.less_equal(y_true, tf.constant(classes_range[i], dtype = y_pred.dtype))))\r\n",
    "            coef = tf.tensor_scatter_nd_update(coef, index,\r\n",
    "                                               tf.ones(tf.shape(index)[0], dtype = 'float32') * classes_factor[i - 1])\r\n",
    "\r\n",
    "        loss = tf.multiply(coef, loss)\r\n",
    "        return tf.reduce_mean(loss)\r\n",
    "\r\n",
    "    model.compile(\r\n",
    "        optimizer, loss=custom_loss, metrics=[\"mape\"]\r\n",
    "    )\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n",
    "tuner = MyTuner(\r\n",
    "    hypermodel=build_model,\r\n",
    "    objective=\"mape\",\r\n",
    "    max_epochs=100,\r\n",
    "    factor=3,\r\n",
    "    hyperband_iterations=1,\r\n",
    "    distribution_strategy=tf.distribute.MirroredStrategy(),\r\n",
    "    directory=\"results_dir\",\r\n",
    "    project_name=\"qr\",\r\n",
    "    overwrite=True\r\n",
    ")\r\n",
    "\r\n",
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n",
    "\r\n",
    "x_train_nonprice=data.iloc[window_size-1:-288].drop(data.columns[[0,-1]],axis=1)\r\n",
    "x_train_price=data.iloc[:-288,0]*10\r\n",
    "y_train=data.iloc[window_size-1:-288]['Target']\r\n",
    "\r\n",
    "x_test_nonprice=data.iloc[-288+window_size-1:].drop(data.columns[[0,-1]],axis=1)\r\n",
    "x_test_price=data.iloc[-288:,0]*10\r\n",
    "y_test=data.iloc[-288+window_size-1:]['Target']\r\n",
    "\r\n",
    "x_train_price=handle_input_window_size(x_train_price.values, window_size)\r\n",
    "x_test_price=handle_input_window_size(x_test_price.values, window_size)\r\n",
    "\r\n",
    "tuner.search(\r\n",
    "    [x_train_nonprice,x_train_price],\r\n",
    "    y_train,\r\n",
    "    validation_data=([x_test_nonprice,x_test_price], y_test),\r\n",
    "    # callbacks=[tf.keras.callbacks.EarlyStopping(\"val_mape\")],\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "1499915ab5bfa5654b63455aae1dae0abfea5e865ea236d455d8c3a0c064d563"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}